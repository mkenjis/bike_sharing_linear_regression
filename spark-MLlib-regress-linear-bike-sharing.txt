val rdd = sc.textFile("bike/hour_nohead.csv").map(x => x.split(","))

def oneHotEncColumns(rddx: org.apache.spark.rdd.RDD[Array[String]], idx: Int):org.apache.spark.rdd.RDD[Array[Double]] = {
  val categories = rddx.map(r => r(idx)).distinct.zipWithIndex.collect.toMap
  val numCategories = categories.size
  val vetcateg = rddx.map(r => {
      val categoryIdx = categories(r(idx)).toInt
      val categoryFeatures = Array.ofDim[Double](numCategories)
      categoryFeatures(categoryIdx) = 1.0
      categoryFeatures
  })
  vetcateg
}

def mergeArray(rddx: org.apache.spark.rdd.RDD[Array[String]], idx: Int*):org.apache.spark.rdd.RDD[Array[Double]] = {
  var i = 0
  var arr1 = oneHotEncColumns(rddx,idx(i))
  for (j <- 1 until idx.size) {
    var arr2 = oneHotEncColumns(rddx,idx(j))
    var flt1 = arr1.zip(arr2).map(x => (x._1.toList ++ x._2.toList).toArray)
    arr1 = flt1
  }
  arr1
}

val concat = mergeArray(rdd,2,5,7,9)

val rdd1 = rdd.map(x => Array(x(16).toDouble,x(6).toDouble,x(8).toDouble,x(10).toDouble,x(11).toDouble,x(12).toDouble,x(13).toDouble))

val vect = rdd1.zip(concat).map(x => (x._1.toList ++ x._2.toList).toArray)

import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint

val data = vect.map(r => {
   val label = r(0).toDouble
   val features = r.slice(1, r.size-1)
   LabeledPoint(label, Vectors.dense(features))
 })

data.cache

val sets = data.randomSplit(Array(0.8,0.2))
val trainSet = sets(0)
val testSet = sets(1)


import org.apache.spark.mllib.regression.LinearRegressionWithSGD
val model = LinearRegressionWithSGD.train(trainSet, 200, 1.0)
----
import org.apache.spark.mllib.regression.LinearRegressionWithSGD
val alg = new LinearRegressionWithSGD()
alg.setIntercept(true)
alg.optimizer.setNumIterations(200)
alg.optimizer.setStepSize(1.0)
val model = alg.run(trainSet)
----
val validPredicts = testSet.map(x => (model.predict(x.features),x.label))

validPredicts.take(10)

import org.apache.spark.mllib.evaluation.RegressionMetrics
val validMetrics = new RegressionMetrics(validPredicts)
validMetrics.rootMeanSquaredError
validMetrics.meanSquaredError


------- Transforming the label data --------------


import java.lang.Math._
val data = vect.map(r => {
   val label = Math.log(r(0).toDouble)
   val features = r.slice(1, r.size-1)
   LabeledPoint(label, Vectors.dense(features))
 })

val sets = data.randomSplit(Array(0.8,0.2))
val trainSet = sets(0)
val testSet = sets(1)


import org.apache.spark.mllib.regression.LinearRegressionWithSGD
val model = LinearRegressionWithSGD.train(trainSet, 200, 1.0)
----
import org.apache.spark.mllib.regression.LinearRegressionWithSGD
val alg = new LinearRegressionWithSGD()
alg.setIntercept(true)
alg.optimizer.setNumIterations(200)
alg.optimizer.setStepSize(1.0)
val model = alg.run(trainSet)
----

val validPredicts = testSet.map(x => (Math.exp(model.predict(x.features)),Math.exp(x.label)))

validPredicts.take(10)

